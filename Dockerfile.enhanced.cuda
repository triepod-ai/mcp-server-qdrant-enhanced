# Use standard Ubuntu for CPU-only mode (no CUDA/GPU dependencies)
FROM ubuntu:22.04

WORKDIR /app

# Install Python 3 and pip
RUN apt-get update && \
    apt-get install -y python3 python3-pip python3-venv && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Copy the source code
COPY . /app

# Install uv for package management
RUN python3 -m pip install --no-cache-dir uv

# Install Python packages with CPU-only ONNX Runtime
RUN uv pip install --system \
    flatbuffers numpy packaging protobuf sympy \
    onnxruntime \
    fastembed>=0.6.0 \
    qdrant-client>=1.12.0 \
    pydantic>=2.10.6 \
    "mcp[cli]>=1.3.0"

# Add source directory to Python path
ENV PYTHONPATH=/app/src

# Set environment variables with defaults
ENV QDRANT_URL=""
ENV QDRANT_API_KEY=""
ENV COLLECTION_NAME="working_solutions"
ENV EMBEDDING_MODEL="sentence-transformers/all-MiniLM-L6-v2"
ENV QDRANT_AUTO_CREATE_COLLECTIONS="true"
ENV QDRANT_ENABLE_QUANTIZATION="true"
ENV QDRANT_HNSW_EF_CONSTRUCT="200"
ENV QDRANT_HNSW_M="16"
ENV EMBEDDING_PROVIDER="fastembed"

# Pre-download embedding models (use CPU providers during build)
RUN python3 -c "\
import sys; \
sys.path.insert(0, 'src'); \
from fastembed import TextEmbedding; \
models_to_download = ['BAAI/bge-large-en-v1.5', 'BAAI/bge-base-en-v1.5', 'BAAI/bge-base-en', 'sentence-transformers/all-MiniLM-L6-v2']; \
print('Pre-downloading embedding models for enhanced multi-vector support...'); \
[print(f'Downloading {model}...') or TextEmbedding(model, providers=['CPUExecutionProvider']) and print(f'✓ {model} downloaded successfully') for model in models_to_download]; \
print('✓ All embedding models pre-downloaded')"

# Use unbuffered output for proper stdio communication
ENV PYTHONUNBUFFERED=1
CMD ["python3", "-u", "-m", "mcp_server_qdrant.enhanced_main", "--transport", "stdio"]